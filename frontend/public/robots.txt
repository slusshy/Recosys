# https://www.robotstxt.org/robotstxt.html
User-agent: *
Allow: /

# Disallow crawling of the following
Disallow: /api/
Disallow: /admin/
Disallow: /private/

# Sitemap location (uncomment and update with your sitemap URL)
# Sitemap: https://your-domain.com/sitemap.xml

# Crawl-delay: 10

# Allow all bots to crawl the website
User-agent: *

# Disallow crawling of specific file types
Disallow: /*.json$
Disallow: /*.xml$
Disallow: /*.js$
Disallow: /*.css$

# Allow media files
Allow: /*.jpg$
Allow: /*.jpeg$
Allow: /*.png$
Allow: /*.gif$
Allow: /*.svg$
Allow: /*.webp$

# Allow font files
Allow: /*.woff$
Allow: /*.woff2$
Allow: /*.ttf$
Allow: /*.eot$

# Disallow query parameters
Disallow: /*?*
Disallow: /*&*

# Disallow hash URLs
Disallow: /*#

# Disallow specific paths
Disallow: /_next/
Disallow: /_astro/
Disallow: /_svelte/
Disallow: /_nuxt/

# Allow all other paths
Allow: /
